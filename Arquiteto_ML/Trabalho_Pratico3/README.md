# Bootcamp XPe: Arquiteto de Machine Learning

## Trabalho Pr√°tico
 **M√≥dulo 3: Sistemas de Recomenda√ß√£o**

## Objetivos de Ensino
**Exercitar os seguintes conceitos trabalhados no M√≥dulo:**

* **1. Dist√¢ncia e similaridade.**
* **2. Recomenda√ß√£o baseada em conte√∫do.**

## Enunciado

**Em um ambiente de desenvolvimento em Python (recomenda-se o Google
Colaboratory), implemente as fun√ß√µes descritas para responder √†s quest√µes
objetivas.**

## Atividades
**Os alunos dever√£o desempenhar as seguintes atividades:**




* **1. Acessar o ambiente Google Colaboratory (recomendado) ou qualquer
ambiente de desenvolvimento em Python.**
* **2. Implementar as seguintes fun√ß√µes em Python:**

**a. Uma fun√ß√£o que calcula a dist√¢ncia euclidiana entre dois vetores x e
y:**

$$\begin{equation}d(x,y) = \sqrt{\sum_{i=1}^{n}(x_i - y_i)^2}=\left\Vert \mathbf{x} - \mathbf{y} \right\Vert2\end{equation}$$

* **Essa f√≥rmula utiliza a diferen√ßa entre os valores de cada dimens√£o dos vetores, elevados ao quadrado, somados e depois tirada a raiz quadrada dessa soma. O resultado √© a dist√¢ncia Euclidiana entre os vetores ùë• e ùë¶.**


```python
# Fun√ß√£o para calcular a dist√¢ncia euclidiana entre dois vetores
import numpy as np

def euclidean_distance(x, y):
    return np.sqrt(np.sum((x - y) ** 2))

```


```python
# Exemplo da fun√ß√£o:
x = np.array([1, 2, 3])
y = np.array([4, 5, 6])
distance = euclidean_distance(x, y)
print(f"A dist√¢ncia euclidiana entre os vetores x e y : {distance}")  

```

    A dist√¢ncia euclidiana entre os vetores x e y : 5.196152422706632
    

* **Interpreta√ß√£o do resultado**:
  * Quanto menor a dist√¢ncia Euclidiana entre dois vetores, maior √© a sua similaridade ou proximidade. 

**b. Uma fun√ß√£o que calcula a dist√¢ncia de Hamming (quantidade de posi√ß√µes distintas) entre dois vetores bin√°rios n-dimensionais x e y:**

**$$\begin{equation}
h(x,y) = \sum_{i=1}^{n} |x_i - y_i|
\end{equation}$$**




```python
# fun√ß√£o que calcula a dist√¢ncia de Hamming:
def hamming_distance(x, y):
    """
    Calcula a dist√¢ncia de Hamming entre dois vetores bin√°rios de mesma dimens√£o.
    
    Argumentos:
    x -- um vetor bin√°rio de dimens√£o n
    y -- um vetor bin√°rio de dimens√£o n
    
    Retorna:
    A dist√¢ncia de Hamming entre x e y
    """
    
    if len(x) != len(y):
        raise ValueError("Os vetores devem ter a mesma dimens√£o")
        
    return sum([1 for i in range(len(x)) if x[i] != y[i]])

```


```python
# Exemplo da Fun√ß√£o:
x = [0, 1, 0, 1, 1, 0]
y = [1, 1, 0, 0, 1, 1]
dist = hamming_distance(x, y)
print(f"A dist√¢ncia de Hamming entre x e y √©:{dist}") 

```

    A dist√¢ncia de Hamming entre x e y √©:3
    

* O resultado significa que existem 3 bits que diferem entre os dois vetores.

**Uma fun√ß√£o que calcula a dist√¢ncia de Hamming normalizada
(quantidade de posi√ß√µes distintas dividida pela dimens√£o dos vetores)
entre dois vetores bin√°rios n-dimensionais x e y:**

$$\begin{equation}
d_{norm}(x,y) = \frac{1}{n}\sum_{i=1}^{n} |x_i - y_i|
\end{equation}$$


```python
# fun√ß√£o que calcula a dist√¢ncia de Hamming normalizada:
def normalized_hamming_distance(x, y):
    """
    Calcula a dist√¢ncia normalizada de Hamming entre dois vetores bin√°rios de mesma dimens√£o.
    
    Argumentos:
    x -- um vetor bin√°rio de dimens√£o n
    y -- um vetor bin√°rio de dimens√£o n
    
    Retorna:
    A dist√¢ncia normalizada de Hamming entre x e y
    """
    
    if len(x) != len(y):
        raise ValueError("Os vetores devem ter a mesma dimens√£o")
        
    n = len(x)
    return sum([x[i] ^ y[i] for i in range(n)]) / n

```


```python
# Exemplo da fun√ß√£o:
x = [0, 1, 0, 1, 1, 0]
y = [1, 1, 0, 0, 1, 1]
dist_norm = normalized_hamming_distance(x, y)
print(f"A dist√¢ncia de Hamming Normalizada entre x e y √©:{dist_norm}")  

```

    A dist√¢ncia de Hamming Normalizada entre x e y √©:0.5
    

* O resultado √© 0.5, significa que existem 3 bits que diferem entre os dois vetores, em uma dimens√£o de 6 bits, o que resulta em uma dist√¢ncia normalizada de 1/2.
* A dist√¢ncia normalizada de Hamming √© simplesmente a contagem m√©dia dos bits que diferem entre os dois vetores.

Uma fun√ß√£o para calcular a similaridade de cossenos entre dois vetores
n-dimensionais x e y:

$$\begin{equation}
\cos(x,y) = \frac{\mathbf{x} \cdot \mathbf{y}}{\left\Vert \mathbf{x} \right\Vert \left\Vert \mathbf{y} \right\Vert} = \frac{\sum_{i=1}^{n} x_i y_i}{\sqrt{\sum_{i=1}^{n} x_i^2}\sqrt{\sum_{i=1}^{n} y_i^2}}
\end{equation}$$


```python
# Fun√ß√£o para o c√°lculo da similaridade de cossenos entre dois vetores:
import math

def cosine_similarity(x, y):
    """
    Calcula a similaridade de cossenos entre dois vetores de mesma dimens√£o.
    
    Argumentos:
    x -- um vetor de dimens√£o n
    y -- um vetor de dimens√£o n
    
    Retorna:
    A similaridade de cossenos entre x e y
    """
    
    if len(x) != len(y):
        raise ValueError("Os vetores devem ter a mesma dimens√£o")
        
    dot_product = sum([x[i] * y[i] for i in range(len(x))])
    norm_x = math.sqrt(sum([x[i]**2 for i in range(len(x))]))
    norm_y = math.sqrt(sum([y[i]**2 for i in range(len(y))]))
    
    return dot_product / (norm_x * norm_y)

```


```python
# Exemplo da fun√ß√£o: com resultado de similaridade.
x = [1, 2, 3, 4, 5]
y = [2, 4, 6, 8, 10]
similarity = cosine_similarity(x, y)
print(f"Resultado da similaridade de cossenos entre x e y:{similarity}")

```

    Resultado da similaridade de cossenos entre x e y:1.0
    

* Os vetores x e y t√™m uma rela√ß√£o linear perfeita (ou seja, um √© um m√∫ltiplo escalar do outro), portanto, a similaridade de cossenos √© 1.0.
* Em caso de resultado 0 indica que os vetores s√£o ortogonais.
* Em caso de -1 indica que os vetores s√£o opostos.

# Exemplo de aplica√ß√µes da dist√¢ncia Euclidiana:

* Aprendizado de m√°quina: A dist√¢ncia Euclidiana √© usada em muitos algoritmos de aprendizado de m√°quina, como k-means clustering, nearest neighbors, regress√£o linear, SVM (Support Vector Machines), etc. Ela √© usada para medir a dist√¢ncia entre os dados de treinamento e os dados de teste e para encontrar a melhor correspond√™ncia entre os dados.

* Processamento de imagens: A dist√¢ncia Euclidiana √© usada para medir a semelhan√ßa entre duas imagens ou partes de imagens. Ela √© usada em algoritmos de detec√ß√£o de objetos, alinhamento de imagens, reconhecimento de faces, etc.

* An√°lise de dados: A dist√¢ncia Euclidiana √© usada para medir a dist√¢ncia entre duas observa√ß√µes ou pontos em um espa√ßo n-dimensional. Ela √© usada em an√°lise de clusters, detec√ß√£o de anomalias, classifica√ß√£o de dados, etc.

* Engenharia mec√¢nica: A dist√¢ncia Euclidiana √© usada para medir a dist√¢ncia entre dois pontos em um espa√ßo tridimensional. Ela √© usada em projetos de engenharia para medir a dist√¢ncia entre pe√ßas, componentes, etc.

* Biologia molecular: A dist√¢ncia Euclidiana √© usada para medir a dist√¢ncia entre duas sequ√™ncias de DNA ou prote√≠nas. Ela √© usada em algoritmos de alinhamento de sequ√™ncias, busca de homologia, etc.

* Economia: A dist√¢ncia Euclidiana √© usada para medir a dist√¢ncia entre duas cidades ou regi√µes com base em suas caracter√≠sticas socioecon√¥micas. Ela √© usada em an√°lise de clusters, previs√£o de demanda, etc.

# Exemplo de Aplica√ß√µes da dist√¢ncia de Hamming:
* Detec√ß√£o e corre√ß√£o de erros: A dist√¢ncia de Hamming pode ser usada para detectar e corrigir erros em c√≥digos de barras, c√≥digos QR, sistemas de comunica√ß√£o sem fio, e outros sistemas de transmiss√£o de dados. Por exemplo, ao codificar informa√ß√µes em um conjunto de bits, pode-se adicionar um n√∫mero fixo de bits de verifica√ß√£o que s√£o calculados usando a dist√¢ncia de Hamming. Quando os dados s√£o recebidos, pode-se comparar os bits de verifica√ß√£o com os dados originais para verificar se houve algum erro de transmiss√£o.

* Processamento de imagens: A dist√¢ncia de Hamming pode ser usada para comparar imagens bin√°rias e determinar a semelhan√ßa entre elas. Por exemplo, pode-se comparar imagens de impress√µes digitais para verificar se elas pertencem √† mesma pessoa.

* Algoritmos de pesquisa: A dist√¢ncia de Hamming pode ser usada para classificar dados em um banco de dados. Por exemplo, pode-se classificar os usu√°rios em um site com base em seus perfis ou classificar produtos em uma loja online com base em seus recursos.

* An√°lise de sequ√™ncias de DNA: A dist√¢ncia de Hamming pode ser usada para comparar sequ√™ncias de DNA e identificar muta√ß√µes. Por exemplo, pode-se comparar o DNA de um paciente com o DNA de um indiv√≠duo saud√°vel para identificar muta√ß√µes que possam causar doen√ßas.

